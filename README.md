#  DS-677 Deep Learning Project using Transformers
## Music Generation

### Melody generation using Transformers

### Trying out RAVE for music Generation

### Music Generation using MIDI Maestro Dataset

#### Try 1

#### Try 2

The MIDI dataset consist of a number of parts (for different instruments) and each part contains a set of instructions setting out what notes are played, when they are played and how they are played ie loudness and speed.

I used the [_pretty_midi_](https://github.com/craffel/pretty-midi) library although another great one is [_music21_](http://web.mit.edu/music21/). With a _pretty_midi_ object it is much clearer to see the music sequence events in a midi file:
[Note(start=1.431250, end=3.357292, pitch=49, velocity=48) ,
Note(start=1.676042, end=3.484375, pitch=52, velocity=43),
Note(start=2.178125, end=3.739583, pitch=57, velocity=54)]
## Text to Image Generation

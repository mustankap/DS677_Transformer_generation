#  DS-677 Deep Learning Project using Transformers
## Music Generation

### Melody generation using Transformers

### Trying out RAVE for music Generation

### Music Generation using MIDI Maestro Dataset

#### Try 1

#### Try 2

The MIDI dataset consist of a number of parts (for different instruments) and each part contains a set of instructions setting out what notes are played, when they are played and how they are played ie loudness and speed.

I used the [_pretty_midi_](https://github.com/craffel/pretty-midi) library although another great one is [_music21_](http://web.mit.edu/music21/). With a _pretty_midi_ object it is much clearer to see the music sequence events in a midi file:
[Note(htarth0.000000, a!d_0.440000, mote(etart.0.064000, entl-0.320000. velocitl-,51, Note(starch0.320.0, endh0.736000, verocity=65), 
Note(start-0.352000, eh...608000, phtch.89, velocity.5), 
Note(ocarth0.608000, phtchha9, velocit,651 
## Text to Image Generation
